{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e348fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook utils\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "def export_to_matlab(output_file, data):\n",
    "    scipy.io.savemat(output_file, mdict={'data': data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07888230",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting Octave client\n",
    "\n",
    "from oct2py import Oct2Py\n",
    "\n",
    "octave = Oct2Py()\n",
    "octave.addpath('../../matlab/');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed00fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Communication Input data model\n",
    "# An ad-hoc object with the images to analyze, the points and the algorithm settings. \n",
    "# Points: Dictionary with the Point ID as key and a ad-hoc object with PositionX, PositionY and a list of the two images (as PIL.Image.Image) as value.\n",
    "# Settings.TimeDelta: Time between two images, iin miliseconds.\n",
    "# Settings.Scale: Image scaling, in pixels per milimeters.\n",
    "# Settings.WindowSize: Interrogation Window size, default is 32.\n",
    "# Settings.RoiSize: Region of Interest size, default is None which will be used as the full image.\n",
    "\n",
    "class InputPIV:\n",
    "    def __init__(self, points, time_delta, scale, window_size=32, roi_size=None):\n",
    "        self.points = points\n",
    "        self.settings = Settings(time_delta, scale, window_size, roi_size)\n",
    "        \n",
    "\n",
    "class Settings:\n",
    "    def __init__(self, time_delta, scale, window_size, roi_size):\n",
    "        self.time_delta = time_delta\n",
    "        self.scale = scale\n",
    "        self.window_size = window_size\n",
    "        self.roi_size = roi_size\n",
    "        \n",
    "\n",
    "class Point:\n",
    "    def __init__(self, pos_x, pos_y, images):\n",
    "        self.pos_x = pos_x\n",
    "        self.pos_y = pos_y\n",
    "        self.images = images\n",
    "\n",
    "\n",
    "## Communication Output data model\n",
    "# An ad-hoc object with the following fields: X, Y, U (X velocity), V (Y velocity) and S2N (signal to noise ratio).\n",
    "\n",
    "class OutputPIV:\n",
    "    def __init__(self, x, y, u, v, s2n):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        self.s2n = s2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8af448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "def first(aList):\n",
    "    return aList[0]\n",
    "\n",
    "def last(aList):\n",
    "    return aList[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d392c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Externals\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "## Reading images\n",
    "# Loading images as an IxJ matrix, containing the intensity of each pixel.\n",
    "#\n",
    "# Output: \n",
    "# Array with the following dimensions: 0 - Image; 1 - Height (Y); 2 - Width (X).\n",
    "\n",
    "IMAGE_1 = '../images/Image 1a.png'\n",
    "IMAGE_2 = '../images/Image 1b.png'\n",
    "\n",
    "def load_images(images_paths=[IMAGE_1, IMAGE_2]):\n",
    "    images = []\n",
    "    \n",
    "    for image in images_paths:\n",
    "        img = Image.open(image)\n",
    "        grayscale_image = img.convert(\"L\")\n",
    "        grayscale_array = np.asarray(grayscale_image)\n",
    "        images += [np.array(grayscale_array)]\n",
    "    \n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "def load_fake_images(y=100, x=None, total_images=5, mode='const'):\n",
    "    if not x:\n",
    "        x = y\n",
    "        \n",
    "    count = 1\n",
    "    images = []\n",
    "    for idx in range(total_images):\n",
    "        if mode == 'rand':\n",
    "            images += [(np.random.rand(y, x) * 100).astype(np.uint8)]\n",
    "        elif mode == 'inc':\n",
    "            images += [np.reshape(np.arange(count, count + y * x), [y, x], order='F')]\n",
    "            count += y * x\n",
    "        else:\n",
    "            images += [np.ones((y, x), np.uint8) * (idx + 1)]\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d06f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Externals\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Single to double frame\n",
    "# Combines images by 2, returning an array with two frames (one for each image). \n",
    "#\n",
    "#   Input: 5 images with step 1.\n",
    "#   Output: 4 double-framed images.\n",
    "#      FrameA:  1  2  3  4\n",
    "#      FrameB:  2  3  4  5\n",
    "#\n",
    "#   Input: 8 images with step 3.\n",
    "#   Output: 5 doubled-framed images.\n",
    "#      FrameA:  1  2  3  4  5\n",
    "#      FrameB:  4  5  6  7  8\n",
    "#\n",
    "# This function also crops the image according to the provided Region of Interest (ROI), that must be passed as:\n",
    "# ROI = [X-start X-end Y-start Y-end], for example: [1 100 1 50].\n",
    "#\n",
    "# Output:\n",
    "# Array with the following dimensions: 0 - Image; 1 - Frame; 2 - Height (Y); 3 - Width (X).\n",
    "\n",
    "def single_to_double_frame(images, step=1, roi=None):\n",
    "    total_images = images.shape[0]\n",
    "\n",
    "    frameA_idx = list(range(0,total_images-step))\n",
    "    frameB_idx = [idx+1 for idx in frameA_idx]\n",
    "\n",
    "    height, width = first(images).shape\n",
    "    mask = np.ones([height, width], np.uint8)\n",
    "\n",
    "    images_double_framed = []\n",
    "    for idx in frameA_idx:\n",
    "        double_frame = [images[frameA_idx[idx]], images[frameB_idx[idx]]]\n",
    "            \n",
    "        if roi and len(roi) == 4:\n",
    "            size_y, size_x = double_frame[0].shape\n",
    "            min_x, max_x = max(0, roi[0]-1), min(roi[1], size_x)\n",
    "            min_y, max_y = max(0, roi[2]-1), min(roi[3], size_x)\n",
    "            \n",
    "            double_frame[0] = np.array(double_frame[0][min_y:max_y, min_x:max_x])\n",
    "            double_frame[1] = np.array(double_frame[1][min_y:max_y, min_x:max_x])\n",
    "\n",
    "        images_double_framed += [double_frame]\n",
    "            \n",
    "    return np.array(images_double_framed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67afe591",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Externals\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.matlib as npmb\n",
    "\n",
    "\n",
    "## Prepare images for PIV\n",
    "# Determine which indices must be used to create the interrogation windows. \n",
    "# It also add a padding dark color to the images.\n",
    "#\n",
    "# Output: Indexes for vectors (MinX, MaxX, MinY, MaxY), the padded images and the interrogation window indexes.\n",
    "\n",
    "def prepare_piv_images(images, window_size, step):\n",
    "    \n",
    "    # Calculating vectors.\n",
    "    min_x = 1 + math.ceil(step)\n",
    "    min_y = 1 + math.ceil(step)\n",
    "    size_y, size_x = first(images)[0].shape\n",
    "    max_x = step * math.floor(size_x / step) - (window_size - 1) + math.ceil(step)\n",
    "    max_y = step * math.floor(size_y / step) - (window_size - 1) + math.ceil(step)\n",
    "    vectors_u = math.floor((max_x - min_x)/step + 1)\n",
    "    vectors_v = math.floor((max_y - min_y)/step + 1)\n",
    "    \n",
    "    # Centering image grid.\n",
    "    pad_x = size_x - max_x\n",
    "    pad_y = size_y - max_y\n",
    "    shift_x = max(0, round((pad_x - min_x) / 2))\n",
    "    shift_y = max(0, round((pad_y - min_y) / 2))\n",
    "    min_x += shift_x\n",
    "    min_y += shift_y\n",
    "    max_x += shift_x\n",
    "    max_y += shift_y\n",
    "    \n",
    "    # Adding a dark padded border to images.\n",
    "    padded_images = []\n",
    "    for idx in range(len(images)):\n",
    "        padded_images += [[]]\n",
    "        for frame in range(2):\n",
    "            image = images[idx][frame]\n",
    "            padded_images[idx] += [np.pad(image, math.ceil(window_size-step), constant_values=image.min())]\n",
    "        padded_images[idx] = np.array(padded_images[idx])\n",
    "    padded_images = np.array(padded_images)\n",
    "    \n",
    "    # Interrogation window indexes for first frame.\n",
    "    padded_size_y, padded_size_x = first(padded_images)[0].shape\n",
    "    min_s0 = npmb.repmat(np.array(np.arange(min_y, max_y + 1, step) - 1)[:, None], 1, vectors_u)\n",
    "    max_s0 = npmb.repmat(np.array(np.arange(min_x, max_x + 1, step) - 1) * padded_size_y, vectors_v, 1)\n",
    "    s0 = np.asarray(min_s0 + max_s0).flatten()[..., np.newaxis, np.newaxis].transpose([1, 2, 0])\n",
    "\n",
    "    min_s1 = npmb.repmat(np.array(np.arange(1, window_size + 1))[:, None], 1, window_size)\n",
    "    max_s1 = npmb.repmat(np.array(np.arange(1, window_size + 1) - 1) * padded_size_y, window_size, 1)\n",
    "    s1 = min_s1 + max_s1\n",
    "\n",
    "    indexes = np.tile(np.asarray(s1)[..., np.newaxis], [1, 1, s0.shape[2]]) + np.tile(s0, [window_size, window_size, 1]) - 1\n",
    "    \n",
    "    return min_x, max_x, min_y, max_y, padded_images, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a90487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Externals\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Cumulative cross correlation\n",
    "# Averages correlation maps from an image stack.\n",
    "#\n",
    "# TODO: This function isn't working properly! Matlab FFT â‰  Numpy FFT.\n",
    "# Should fix the cross correlation calculation and also check the normalization (different shape expected).\n",
    "#\n",
    "# Output: A correlation matrix with the same size as the images input.\n",
    "\n",
    "NORMALIZED_CORRELATION_RESOLUTION = 2**8\n",
    "def cumulative_cross_correlation(images, indexes, window_size):\n",
    "    \n",
    "    total_correlation = 0\n",
    "    for idx, image in enumerate(images):\n",
    "        frame_a = image[0].take(indexes).astype(np.single)\n",
    "        frame_b = image[1].take(indexes).astype(np.single)\n",
    "        \n",
    "        # Calculating cross correlation\n",
    "        fft_a = np.fft.fft2(frame_a)\n",
    "        fft_b = np.fft.fft2(frame_b)\n",
    "\n",
    "        fft_shifting = np.real(np.fft.ifft(np.fft.ifft(np.conj(fft_a) * fft_b, window_size, 1), window_size, 0))\n",
    "        correlation = np.fft.fftshift(np.fft.fftshift(fft_shifting, 2), 1)\n",
    "        correlation[correlation < 0] = 0\n",
    "        \n",
    "        # Normalizing correlation\n",
    "        min_corr = np.tile(correlation.min(0).min(0), [correlation.shape[0], correlation.shape[1], 1])\n",
    "        max_corr = np.tile(correlation.max(0).max(0), [correlation.shape[0], correlation.shape[1], 1])\n",
    "        norm_corr = (correlation - min_corr) / (max_corr - min_corr) * (NORMALIZED_CORRELATION_RESOLUTION - 1)\n",
    "    \n",
    "        total_correlation += norm_corr/len(images)\n",
    "        \n",
    "    return total_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cec7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Externals\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "\n",
    "\n",
    "## Vector field determination\n",
    "# Here it's where magic happens, calculating peaks and doing science stuff to get the proper PIV data.\n",
    "#\n",
    "# Output: OutputPIV object\n",
    "\n",
    "S2N_FILTER = False\n",
    "DEFAULT_S2N_THRESHOLD = 1\n",
    "DEFAULT_RES_NORMALIZATION = 255\n",
    "def vector_field_determination(correlation, int_window, step, min_x, max_x, min_y, max_y):\n",
    "    \n",
    "    # Normalize result\n",
    "    squeezed_min_corr = correlation.min(0).min(0).squeeze()[:, np.newaxis, np.newaxis]\n",
    "    squeezed_delta_corr = correlation.max(0).max(0).squeeze()[:, np.newaxis, np.newaxis] - squeezed_min_corr\n",
    "    min_res = np.tile(squeezed_min_corr, [1, correlation.shape[0], correlation.shape[1]]).transpose([1, 2, 0])\n",
    "    delta_res = np.tile(squeezed_delta_corr, [1, correlation.shape[0], correlation.shape[1]]).transpose([1, 2, 0])\n",
    "    corr = ((correlation - min_res) / delta_res) * DEFAULT_RES_NORMALIZATION\n",
    "    \n",
    "    # Find peaks and S2N\n",
    "    x1, y1, indexes1, x2, y2, indexes2, s2n = find_all_displacements(corr)\n",
    "    \n",
    "    # Sub-pixel determination\n",
    "    pixel_offset = 1 if (int_window % 2 == 0) else 0.5\n",
    "    vector = sub_pixel_gaussian(corr, int_window, x1, y1, indexes1, pixel_offset)\n",
    "    \n",
    "    # Create data\n",
    "    x_range = np.arange(min_x, max_x + 1, step)\n",
    "    y_range = np.arange(min_y, max_y + 1, step)\n",
    "    output_x = np.tile(x_range + int_window / 2, [len(y_range), 1])\n",
    "    output_y = np.tile(y_range[:, None] + int_window / 2, [1, len(x_range)])\n",
    "    vector = np.reshape(vector, np.append(np.array(output_x.transpose().shape), 2), order='F').transpose([1, 0, 2])\n",
    "\n",
    "    # Signal to noise filter\n",
    "    s2n = s2n[np.reshape(np.array(range(output_x.size)), output_x.transpose().shape, order='F').transpose()]\n",
    "    if S2N_FILTER:\n",
    "        vector[:,:,0] = vector[:,:,0] * (s2n > DEFAULT_S2N_THRESHOLD)\n",
    "        vector[:,:,1] = vector[:,:,1] * (s2n > DEFAULT_S2N_THRESHOLD)\n",
    "    \n",
    "    output_u = vector[:,:,0]\n",
    "    output_v = vector[:,:,1]\n",
    "\n",
    "    output_x -= int_window/2\n",
    "    output_y -= int_window/2\n",
    "\n",
    "    return OutputPIV(output_x, output_y, output_u, output_v, s2n)\n",
    "    \n",
    "    \n",
    "## Gaussian sub-pixel mode\n",
    "# No f*cking clue what this does. Crazy math shit.\n",
    "#\n",
    "# Output: A vector with a sub-pixel deviation - Maybe? I'm not sure. Its dimensions are Number-of-Correlations by 2. \n",
    "\n",
    "def sub_pixel_gaussian(correlation, int_window, x, y, indexes, pixel_offset):\n",
    "    z = np.array(range(indexes.shape[0])).transpose()\n",
    "    \n",
    "    xi = np.nonzero(np.logical_not(np.logical_and(\n",
    "        # Adjusting -1 to -2 according to Matlab/Python mapping.\n",
    "        np.logical_and(x <= correlation.shape[1] - 2, y <= correlation.shape[0] - 2),\n",
    "        np.logical_and(x >= 2, y >= 2)\n",
    "    )))[0]\n",
    "\n",
    "    x = np.delete(x, xi)\n",
    "    y = np.delete(y, xi)\n",
    "    z = np.delete(z, xi)\n",
    "    x_max = correlation.shape[1]\n",
    "    vector = np.ones((correlation.shape[2], 2)) * np.nan\n",
    "\n",
    "    if len(x) > 0:\n",
    "        ip = np.ravel_multi_index(np.array([x, y, z]), correlation.shape, order='F')\n",
    "        flattened_correlation = correlation.flatten(order='F')\n",
    "\n",
    "        f0 = np.log(flattened_correlation[ip])\n",
    "        f1 = np.log(flattened_correlation[ip - 1])\n",
    "        f2 = np.log(flattened_correlation[ip + 1])\n",
    "        peak_y = y + (f1 - f2) / (2 * f1 - 4 * f0 + 2 * f2)\n",
    "\n",
    "        f1 = np.log(flattened_correlation[ip - x_max])\n",
    "        f2 = np.log(flattened_correlation[ip + x_max])\n",
    "        peak_x = y + (f1 - f2) / (2 * f1 - 4 * f0 + 2 * f2)\n",
    "    \n",
    "        sub_pixel_x = peak_x - (int_window / 2) - pixel_offset\n",
    "        sub_pixel_y = peak_y - (int_window / 2) - pixel_offset\n",
    "    \n",
    "        vector[z, :] = np.array([sub_pixel_x, sub_pixel_y]).transpose()\n",
    "    \n",
    "    return vector\n",
    "\n",
    "    \n",
    "## Find all displacements\n",
    "# Find all integer pixel displacement in a stack of correlation windows.\n",
    "#\n",
    "# Output: Horizontal and vertical indexes of the first and second maximum for each slice of correlation in the third\n",
    "# dimension (PeakX1, PeackY1, PeakX2, PeakY2), the absolute indexes of the correlation maximums (Idx1, Idx2) and the\n",
    "# ratio between the first and second peack (S2N) - 0 indicates non confiable results.\n",
    "\n",
    "def find_all_displacements(correlation):\n",
    "    corr_size = correlation.shape[0]\n",
    "    \n",
    "    # Finding first peak\n",
    "    peak1_val, peak1_x, peak1_y, peak_indexes1, peak_positions1 = find_peaks(correlation)\n",
    "\n",
    "    # Finding second peak (1 extra point from Matlab size)\n",
    "    filter_size = 10 if corr_size >= 64 else 5 if corr_size >= 32 else 4\n",
    "    filtered = scipy.ndimage.correlate(peak_positions1, np.ones([filter_size, filter_size, 1]), mode='constant')\n",
    "    correlation = (1 - filtered) * correlation\n",
    "    peak2_val, peak2_x, peak2_y, peak_indexes2, _ = find_peaks(correlation)\n",
    "\n",
    "    # Calculating Signal to Noise ratio\n",
    "    signal_to_noise = np.zeros([peak1_val.shape[0]])\n",
    "    signal_to_noise[peak2_val != 0] = peak1_val[peak2_val != 0] / peak2_val[peak2_val != 0]\n",
    "\n",
    "    # Maximum at a border usually indicates that MAX took the first one it found, so we should put a bad S2N, like 0.\n",
    "    signal_to_noise[peak1_y == 0] = 0\n",
    "    signal_to_noise[peak1_x == 0] = 0\n",
    "    signal_to_noise[peak1_y == (corr_size - 1)] = 0\n",
    "    signal_to_noise[peak1_x == (corr_size - 1)] = 0\n",
    "    signal_to_noise[peak2_y == 0] = 0\n",
    "    signal_to_noise[peak2_x == 0] = 0\n",
    "    signal_to_noise[peak2_y == (corr_size - 1)] = 0\n",
    "    signal_to_noise[peak2_x == (corr_size - 1)] = 0\n",
    "    \n",
    "    return peak1_x, peak1_y, peak_indexes2, peak2_x, peak2_y, peak_indexes2, signal_to_noise\n",
    "    \n",
    "    \n",
    "## Find peaks\n",
    "# Find max values for each correlation.\n",
    "#\n",
    "# Output: The MAX peak, its coordinates (X and Y) and the indexes.\n",
    "    \n",
    "def find_peaks(correlation):\n",
    "    corr_size = correlation.shape[0]\n",
    "    corr_numbers = correlation.shape[2]\n",
    "    max_peak = correlation.max(0).max(0)\n",
    "    max_positions = correlation == np.tile(max_peak[np.newaxis, np.newaxis, ...], [corr_size, corr_size, 1])\n",
    "    max_indexes = np.where(max_positions.transpose(2, 1, 0).flatten())[0]\n",
    "    peak_y, peak_x, peak_z = np.unravel_index(max_indexes, (corr_size, corr_size, corr_numbers), order='F')\n",
    "\n",
    "    # If two elements equals to the max we should check if they are in the same layer and take the first one.\n",
    "    # Surely the second one will be the second highest peak. Anyway this would be a bad vector.\n",
    "    unique_max_indexes = np.unique(peak_z)\n",
    "    max_indexes = max_indexes[unique_max_indexes]\n",
    "    peak_x = peak_x[unique_max_indexes]\n",
    "    peak_y = peak_y[unique_max_indexes]\n",
    "    \n",
    "    return max_peak, peak_x, peak_y, max_indexes, max_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a3c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Externals\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "\n",
    "## Filter fields (WIP)\n",
    "# Applies different filters on the vector fields.\n",
    "#\n",
    "# Output: OutputPIV object, with filtered data.\n",
    "\n",
    "B = 1\n",
    "EPSILON = 0.02\n",
    "DEFAULT_THRESH = 1.5\n",
    "DEFAULT_STD_THRESHOLD = 4\n",
    "def filter_fields(data, std_threashold=DEFAULT_STD_THRESHOLD):\n",
    "    # Filter 1: Threshold on signal to noise.  \n",
    "    data.u = remove_nans(data.u)\n",
    "    data.v = remove_nans(data.v)\n",
    "    \n",
    "    # Filter 2:\n",
    "    mean_u = np.mean(data.u)\n",
    "    mean_v = np.mean(data.v)\n",
    "    std_u = np.std(data.u, ddof=1)\n",
    "    std_v = np.std(data.v, ddof=1)\n",
    "    min_u = mean_u - std_threashold * std_u\n",
    "    max_u = mean_u + std_threashold * std_u\n",
    "    min_v = mean_v - std_threashold * std_v\n",
    "    max_v = mean_v + std_threashold * std_u\n",
    "    data.u[data.u < min_u] = np.nan\n",
    "    data.u[data.u > max_u] = np.nan\n",
    "    data.v[data.v < min_v] = np.nan\n",
    "    data.v[data.v > max_v] = np.nan\n",
    "    \n",
    "    # Filter 3:\n",
    "    size_y, size_x = data.u.shape\n",
    "    normal_fluctuation = np.zeros(shape=(size_y, size_x, 2))\n",
    "    for it in range(2):\n",
    "        velocity_comparator = data.u if it == 0 else data.v\n",
    "        neighbors = np.empty(shape=(size_y - 2, size_x - 2, 2 * B + 1, 2 * B + 1))\n",
    "    \n",
    "        for ii in range(-B, B + 1):\n",
    "            for jj in range(-B, B + 1):\n",
    "                ii_start = 1 + B - 1 + ii\n",
    "                ii_end = -B + ii if -B + ii < 0 else None\n",
    "                jj_start = 1 + B - 1 + jj\n",
    "                jj_end = -B + jj if -B + jj < 0 else None\n",
    "            \n",
    "                ii_neighbors = ii + 2 * B - 1\n",
    "                jj_neighbors = jj + 2 * B - 1\n",
    "            \n",
    "                neighbors[:, :, ii_neighbors, jj_neighbors] = velocity_comparator[ii_start:ii_end, jj_start:jj_end]\n",
    "    \n",
    "        first_neighbors = np.arange((2 * B + 1) * B + B)\n",
    "        last_neighbors = np.arange((2 * B + 1) * B + B + 1, (2 * B + 1)**2)\n",
    "        neighbors_column = np.reshape(neighbors, [neighbors.shape[0], neighbors.shape[1], (2 * B + 1)**2], order='F')\n",
    "        neighbors_column2 = neighbors_column[:, :, np.append(first_neighbors, last_neighbors)].transpose([2, 0, 1])\n",
    "    \n",
    "        median = np.median(neighbors_column2, axis=0).transpose()\n",
    "        velocity_comparator2 = velocity_comparator[B:-B, B:-B]\n",
    "        fluctuation = velocity_comparator2 - median.transpose()\n",
    "        result = neighbors_column2 - np.tile(median, [(2 * B + 1)**2 - 1, 1, 1]).transpose([0, 2, 1])\n",
    "    \n",
    "        median_result = np.median(np.abs(result), axis=0)\n",
    "        normal_fluctuation[B:-B, B:-B, it] = np.abs(fluctuation / (median_result + EPSILON))\n",
    "    \n",
    "    info = np.sqrt(normal_fluctuation[:, :, 0] ** 2 + normal_fluctuation[:, :, 1] ** 2) > DEFAULT_THRESH\n",
    "    data.u[info] = np.nan\n",
    "    data.v[info] = np.nan\n",
    "                \n",
    "    # Inpaint NANs\n",
    "    data.u = inpaint_nans(data.u)\n",
    "    data.v = inpaint_nans(data.v)\n",
    "    \n",
    "    # Filter 4:\n",
    "    try:\n",
    "        \n",
    "        # Trying to apply the smooth predictor.\n",
    "        data.u = smooth(data.u)\n",
    "        data.v = smooth(data.v)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        # Applying Gaussian filter instead.\n",
    "        gfilter = gaussian_filter(5, 1)\n",
    "        data.u = scipy.ndimage.convolve(data.u, gfilter, mode='nearest')\n",
    "        data.v = scipy.ndimage.convolve(data.v, gfilter, mode='nearest')\n",
    "    \n",
    "    return data\n",
    "    \n",
    "\n",
    "## Remove NANs\n",
    "# Replace all the NANs from a data vector with a custom interpolation calculated with its values.\n",
    "#\n",
    "# Output: A matrix with the same dimensions ang items as the input, but with NANs replaced.\n",
    "\n",
    "DEFAULT_PATCH_SIZE = 1\n",
    "def remove_nans(data, patch_size=DEFAULT_PATCH_SIZE):\n",
    "    both_nan_indexes = list(zip(*np.where(np.isnan(data))))\n",
    "    size_y, size_x = data.shape\n",
    "\n",
    "    fixed_data = data.copy()\n",
    "    for y_idx, x_idx in both_nan_indexes:\n",
    "        sample = data[\n",
    "            max(0, y_idx - patch_size):min(size_y, y_idx + patch_size + 1), \n",
    "            max(0, x_idx - patch_size):min(size_x, x_idx + patch_size + 1)\n",
    "        ]\n",
    "\n",
    "        sample = sample[~np.isnan(sample)]\n",
    "        new_data = np.median(sample) if sample.size > 0 else 0\n",
    "\n",
    "        fixed_data[y_idx, x_idx] = new_data\n",
    "\n",
    "    return fixed_data\n",
    "\n",
    "\n",
    "# Inpaint NANs\n",
    "# Solves approximation to one of several pdes to interpolate and extrapolate holes in an array.\n",
    "# It uses a spring metaphor, assuming they (with a nominal length of zero) connect each node with every neighbor \n",
    "# (horizontally, vertically and diagonally). Since each node tries to be like its neighbors, extrapolation is as a \n",
    "# constant function where this is consistent with the neighboring nodes.\n",
    "#\n",
    "# Output: A matrix with the same dimensions ang items as the input, but with NANs replaced.\n",
    "\n",
    "DEFAULT_SPRING_ITERATIONS = 4\n",
    "def inpaint_nans(data, iterations=DEFAULT_SPRING_ITERATIONS):\n",
    "    size_y, size_x = data.shape\n",
    "    flattened = data.flatten(order='F')\n",
    "\n",
    "    # List the nodes which are known, and which will be interpolated.\n",
    "    nan_indexes = np.where(np.isnan(flattened))[0]\n",
    "    known_indexes = np.where(~np.isnan(flattened))[0]\n",
    "\n",
    "    # Get total NANs overall.\n",
    "    nan_count = nan_indexes.size\n",
    "\n",
    "    # Convert NAN indexes to [Row, Column] form.\n",
    "    indexes_y, indexes_x = np.unravel_index(nan_indexes, (size_y, size_x), order='F')\n",
    "\n",
    "    # All forms of index in one array: 0 - Unrolled ; 1 - Row ; 2 - Column\n",
    "    nan_list = np.array([nan_indexes, indexes_y, indexes_x]).transpose() + 1\n",
    "\n",
    "    # Spring analogy - interpolating operator.\n",
    "    # List of all springs between a node and a horizontal or vertical neighbor.\n",
    "    hv_list = np.array([[-1, -1, 0], [1, 1, 0], [-size_y, 0, -1], [size_y, 0, 1]])\n",
    "    hv_springs = np.empty((0, 2))\n",
    "\n",
    "    for it in range(iterations):\n",
    "        hvs = nan_list + np.tile(hv_list[it, :], (nan_count, 1))\n",
    "        k = np.logical_and(\n",
    "            np.logical_and(hvs[:, 1] >= 1, hvs[:, 1] <= size_y),\n",
    "            np.logical_and(hvs[:, 2] >= 1, hvs[:, 2] <= size_x)\n",
    "        )\n",
    "        hv_springs = np.append(hv_springs, np.array([nan_list[k, 0], hvs[k, 0]]).transpose(), axis=0)\n",
    "    \n",
    "    # Delete replicate springs    \n",
    "    hv_springs.sort(axis=1)\n",
    "    hv_springs = np.unique(hv_springs, axis=0) - 1\n",
    "\n",
    "    # Build sparse matrix of connections.\n",
    "    # Springs connecting diagonal neighbors are weaker than the horizontal and vertical ones.\n",
    "    nhv = hv_springs.shape[0]\n",
    "    I, V = np.tile(np.arange(0, nhv)[:, None], (1, 2)).flatten(), np.tile([1, -1], (nhv, 1)).flatten()\n",
    "    springs = scipy.sparse.csr_matrix((V, (I, hv_springs.flatten())), shape=(nhv, data.size))\n",
    "    springs.eliminate_zeros()\n",
    "\n",
    "    # Eliminate knowns\n",
    "    rhs = springs[:, known_indexes] * flattened[known_indexes] * -1\n",
    "\n",
    "    # Solve problem\n",
    "    output = flattened\n",
    "    solution, _, _, _, _, _, _, _, _ ,_ = scipy.sparse.linalg.lsqr(springs[:, nan_indexes], rhs) \n",
    "    output[nan_indexes] = solution\n",
    "\n",
    "    return np.reshape(output, (size_x, size_y)).transpose()\n",
    "\n",
    "\n",
    "## Smooth predictor (WIP)\n",
    "# Fast, automatized and robust discretized spline smoothing for data of arbitrary dimension.\n",
    "# Automatically smoothes the uniformly-sampled input array. It can be any N-D noisy array (time series, images, \n",
    "# 3D data, ...). Non finite data (NaN or Inf) are treated as missing values.\n",
    "#\n",
    "# Output: A matrix with the same dimensions ang items as the input, but with NANs replaced.\n",
    "\n",
    "def smooth(data):\n",
    "    return octave.smoothn(data)\n",
    "\n",
    "    \n",
    "## Gaussian filter\n",
    "# Returns a Gaussian filter with the same implementation as Matlab.\n",
    "#\n",
    "# Output: A matrix that works as a Gaussian filter.\n",
    "\n",
    "def gaussian_filter(size=3, sigma=0.5):\n",
    "    m,n = [(ss-1.)/2. for ss in (size, size)]\n",
    "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
    "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
    "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fead6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate PIV\n",
    "# Generate the PIV data from the images loaded with the input parameters.\n",
    "#\n",
    "# Output: OutputPIV object\n",
    "\n",
    "DEFAULT_OVERLAP = 0.5\n",
    "def PIV(images, int_window, overlap=DEFAULT_OVERLAP):\n",
    "    step = round(int_window * overlap)\n",
    "    min_x, max_x, min_y, max_y, padded_images, indexes = prepare_piv_images(images, int_window, step)\n",
    "    cross_correlation = cumulative_cross_correlation(padded_images, indexes, int_window)\n",
    "    raw_piv_data = vector_field_determination(cross_correlation, int_window, step, min_x, max_x, min_y, max_y)\n",
    "    filtered_piv_data = filter_fields(raw_piv_data)\n",
    "\n",
    "    filtered_piv_data.x = filtered_piv_data.x.transpose()\n",
    "    filtered_piv_data.y = filtered_piv_data.y.transpose()\n",
    "    filtered_piv_data.u = filtered_piv_data.u.transpose()\n",
    "    filtered_piv_data.v = filtered_piv_data.v.transpose()\n",
    "    filtered_piv_data.s2n = filtered_piv_data.s2n.transpose()\n",
    "    \n",
    "    return filtered_piv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "268dd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Externals\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Communication Exceptions\n",
    "# Exception thrown when some parameters weren't passed as expected.\n",
    "        \n",
    "class InvalidParametersError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "## Prepare output\n",
    "# Get the velocity for the desired point. If it is not possible, it will get it for the closest point.\n",
    "#\n",
    "# Output: OutputPIV object\n",
    "\n",
    "def prepare_output(center_x, center_y, piv_data):\n",
    "    idx_x = (np.abs(piv_data.x[:,1] - center_x)).argmin()\n",
    "    idx_y = (np.abs(piv_data.y[1,:] - center_y)).argmin()\n",
    "\n",
    "    position_x = int(piv_data.x[idx_x,1]) + 1\n",
    "    position_y = int(piv_data.y[1,idx_y]) + 1\n",
    "    velocity_x = piv_data.u[idx_x,idx_y]\n",
    "    velocity_y = piv_data.v[idx_x,idx_y]\n",
    "    signal_to_noise = piv_data.s2n[idx_x,idx_y]\n",
    "    \n",
    "    return OutputPIV(position_x, position_y, velocity_x, velocity_y, signal_to_noise)\n",
    "\n",
    "\n",
    "## Entrypoint\n",
    "# Retrieve the images, prepare them and calculate the PIV computation.\n",
    "#\n",
    "# Output: OutputPIV object\n",
    "\n",
    "DEFAULT_INTERROGATION_WINDOW = 32\n",
    "def calculate_piv(frontend_data):\n",
    "    results = {}\n",
    "    settings = frontend_data.settings\n",
    "    \n",
    "    # TODO: Check if this could be parallelized to increase performance.\n",
    "    for point_id, point_data in frontend_data.points.items():\n",
    "\n",
    "        double_framed_images = single_to_double_frame(point_data.images)\n",
    "        if double_framed_images.size <= 2:\n",
    "            raise InvalidParametersError(f'Not enough images passed for point {point_id}')\n",
    "            \n",
    "        shift_x = 0\n",
    "        shift_y = 0\n",
    "        if settings.roi_size is not None:\n",
    "            roi_shift = int(settings.roi_size / 2)\n",
    "            shift_x = point_data.pos_x - roi_shift\n",
    "            shift_y = point_data.pos_y - roi_shift\n",
    "        \n",
    "        piv_data = PIV(double_framed_images, settings.window_size)\n",
    "        piv_data.x = piv_data.x * settings.scale + shift_x\n",
    "        piv_data.y = piv_data.y * settings.scale + shift_y\n",
    "        piv_data.u = piv_data.u * settings.scale / settings.time_delta\n",
    "        piv_data.v = piv_data.v * settings.scale / settings.time_delta\n",
    "        \n",
    "        point_results = prepare_output(point_data.pos_x - 1, point_data.pos_y - 1, piv_data)\n",
    "        results[point_id] = point_results\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df83655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = load_images()\n",
    "window_size, overlap = 32, 0.5\n",
    "\n",
    "step = round(window_size * overlap)\n",
    "double_framed = single_to_double_frame(inputs)\n",
    "min_x, max_x, min_y, max_y, images, indexes = prepare_piv_images(double_framed, window_size, step)\n",
    "\n",
    "## CUMULATIVE CROSS CORRELATION\n",
    "\n",
    "NORMALIZED_CORRELATION_RESOLUTION = 2**8\n",
    "    \n",
    "total_correlation = 0\n",
    "for idx, image in enumerate(images):\n",
    "    frame_a = image[0].take(indexes).astype(np.single)\n",
    "    frame_b = image[1].take(indexes).astype(np.single)\n",
    "        \n",
    "    # Calculating cross correlation\n",
    "    fft_a = np.fft.fft2(frame_a)\n",
    "    fft_b = np.fft.fft2(frame_b)\n",
    "\n",
    "    fft_shifting = np.real(np.fft.ifft(np.fft.ifft(np.conj(fft_a) * fft_b, window_size, 1), window_size, 0))\n",
    "    correlation = np.fft.fftshift(np.fft.fftshift(fft_shifting, 2), 1)\n",
    "    correlation[correlation < 0] = 0\n",
    "        \n",
    "    # Normalizing correlation\n",
    "    min_corr = np.tile(correlation.min(0).min(0), [correlation.shape[0], correlation.shape[1], 1])\n",
    "    max_corr = np.tile(correlation.max(0).max(0), [correlation.shape[0], correlation.shape[1], 1])\n",
    "    norm_corr = (correlation - min_corr) / (max_corr - min_corr) * (NORMALIZED_CORRELATION_RESOLUTION - 1)\n",
    "    \n",
    "    total_correlation += norm_corr/len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "79d10ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = load_images()\n",
    "window_size, overlap = 32, 0.5\n",
    "\n",
    "step = round(window_size * overlap)\n",
    "double_framed = single_to_double_frame(inputs)\n",
    "min_x, max_x, min_y, max_y, images, indexes = prepare_piv_images(double_framed, window_size, step)\n",
    "\n",
    "## CUMULATIVE CROSS CORRELATION\n",
    "    \n",
    "total_correlation = 0\n",
    "for idx, image in enumerate(images):\n",
    "    frame_a = image[0].flatten(order='F').take(indexes).astype(np.single)\n",
    "    frame_b = image[1].flatten(order='F').take(indexes).astype(np.single)\n",
    "        \n",
    "    # Calculating cross correlation\n",
    "    correlation = octave.correlate(frame_a, frame_b, window_size)\n",
    "        \n",
    "    # Normalizing correlation\n",
    "    min_corr = np.tile(correlation.min(0).min(0), [correlation.shape[0], correlation.shape[1], 1])\n",
    "    max_corr = np.tile(correlation.max(0).max(0), [correlation.shape[0], correlation.shape[1], 1])\n",
    "    norm_corr = (correlation - min_corr) / (max_corr - min_corr) * (NORMALIZED_CORRELATION_RESOLUTION - 1)\n",
    "    \n",
    "    total_correlation += norm_corr/len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "03ee589c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[150.54735 , 163.85245 , 175.57785 , 183.57521 , 179.56801 ],\n",
       "        [130.88586 , 143.8335  , 151.7764  , 158.77962 , 155.92657 ],\n",
       "        [114.92517 , 125.207016, 134.20534 , 137.34096 , 136.87793 ],\n",
       "        [109.70593 , 116.26657 , 121.80243 , 123.940506, 125.8709  ],\n",
       "        [112.78027 , 116.784065, 115.0205  , 113.21266 , 116.37892 ]],\n",
       "       dtype=float32),\n",
       " array([[  0.        ,   0.        ,  29.02635984,  44.20187396,\n",
       "           0.        ],\n",
       "        [  0.        ,  12.39216791,   0.        ,   7.84717792,\n",
       "           0.        ],\n",
       "        [ 31.61917328,  22.13879916, 112.91599092,  85.16986718,\n",
       "           0.        ],\n",
       "        [  0.        ,   0.96791558,   0.        ,   2.45109429,\n",
       "           0.        ],\n",
       "        [  0.        ,   0.        ,  23.32560112,  16.4664921 ,\n",
       "           0.        ]]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correlation[0:5,0:5,0], total_correlation2[0:5,0:5,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
